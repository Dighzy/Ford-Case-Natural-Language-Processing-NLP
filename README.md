# üöÄ NLP Multi-Output Classification

## üìå What Was Done
- **Objective**: Classify customer complaints using NLP.
- **Model**: BERT embeddings + feature engineering.
- **Outputs**:
  - **Multi-class classification**: Issue category.
- **Training**: Used **BCELoss** and **CrossEntropyLoss**..
- **Prediction**: Classifies complaints into multi category labels.


## Project Structure

```bash
‚îú‚îÄ‚îÄ .git/               # Git directory
‚îú‚îÄ‚îÄ data/               # Data used in the project
‚îú‚îÄ‚îÄ models/             # Trained or pre-trained models
‚îú‚îÄ‚îÄ notebooks/          # Jupyter Notebooks for analysis and code
‚îú‚îÄ‚îÄ src/                # Main source code of the project
‚îú‚îÄ‚îÄ tests/              # Unit and integration tests
‚îú‚îÄ‚îÄ .gitattributes      # Git-specific configurations
‚îú‚îÄ‚îÄ .gitignore          # Files and folders ignored by Git
‚îú‚îÄ‚îÄ env.yml             # Conda environment configuration
‚îú‚îÄ‚îÄ LICENSE             # Project license
‚îú‚îÄ‚îÄ README.md           # Main documentation
‚îú‚îÄ‚îÄ Report.docx         # Project report
‚îú‚îÄ‚îÄ set_up.py           # Initial setup script
‚îú‚îÄ‚îÄ TesteNLP.md         # Notes and tests related to NLP
```

## Project Setup

To set up the project environment, you have two options. You can either use the `setup.py` script or create the environment manually using the `env.yml` file. Choose the option that works best for you.

### Option 1: Using the `setup.py` script

1. Make sure you have Python and `pip` installed on your machine.
2. Run the following command in the terminal to install the required dependencies:

   ```bash
   python setup.py install
   ```

### Option 2: Using the `env.yml` file

1. Ensure that you have Conda installed on your machine.
2. Create the environment using the following command:

   ```bash
   conda env create -f env.yml
   ```

 3. Once the environment is created, activate it with:
      ```bash
    conda activate ford_case_iel
      ```


### Etapas Obrigat√≥rias:
 Marque as etapas que conseguir completar, sabemos q este √© um teste complexo e que o tempo n√£o √© dos mais favoraveis, mas um dos pontos a se considerar ser√° a produtividade do candidato, n√£o q mt codigo apenas sej√° algo produtivo :)

1. **[x] Aquisi√ß√£o e Pr√©-processamento de Dados**: Automatizar o download dos dados da NHTSA. Realizar o pr√©-processamento necess√°rio, incluindo limpeza de texto (remo√ß√£o de caracteres especiais, tratamento de stop words, stemming ou lematiza√ß√£o), e transforma√ß√£o em um formato adequado para o treinamento do modelo. Documentar todas as etapas e justificar as escolhas realizadas.

2. **[x] Engenharia de Features**: Criar recursos relevantes a partir do texto das reclama√ß√µes. Isso pode incluir, mas n√£o se limita a: embeddings de palavras ou senten√ßas, word count, TF-IDF, n-grams, sentimento, t√≥picos extra√≠dos via LDA ou modelos similares. Documentar o processo e a escolha dos recursos.

3. **[x] Treinamento do Modelo**: Treinar um modelo usando as features criadas. Justificar a escolha do modelo e da arquitetura (se aplic√°vel), considerando as caracter√≠sticas dos dados e a tarefa de classifica√ß√£o/Clusteriza√ß√£o/Regress√£o escolhida. Monitorar o treinamento e registrar m√©tricas relevantes (precis√£o, recall, F1-score, AUC, etc.) para avaliar a performance do modelo.

4. **[x] Deploy e Versionamento**: Implementar o deploy do modelo treinado utilizando ferramentas de versionamento de c√≥digo (como Git) e gerenciamento de pacotes (como pip ou conda). A solu√ß√£o deve ser facilmente reproduz√≠vel.

5. **[x] Relat√≥rio e An√°lise Estat√≠stica**: Gerar um relat√≥rio conciso que inclua:
    - Descri√ß√£o (ou desenho (desenho conta mais kkk)) da pipeline de processamento de dados.
    - An√°lise estat√≠stica descritiva dos dados, com gr√°ficos relevantes (histogramas, boxplots, etc.) e coment√°rios interpretando os resultados, n√£o vale s√≥ plotar graficozinho.
    - Detalhes sobre o modelo escolhido, incluindo a arquitetura (se aplic√°vel) e justificativa para a sua escolha.
    - Resultados do treinamento, incluindo as m√©tricas de avalia√ß√£o e uma an√°lise da performance do modelo.
    - Discuss√£o sobre os pontos fortes e fracos da solu√ß√£o.

### Etapas Opcionais (para candidatos com maior experi√™ncia):

1. **[ ] Avalia√ß√£o de Data Drift**: Utilizar um outro conjunto de dados da NHTSA (por exemplo, de um per√≠odo diferente) para avaliar a robustez do modelo treinado e detectar a presen√ßa de data drift.

2. **[x] API ou Script de Consumo**: Criar uma API REST simples (ou um script) que permita consumir o modelo treinado e fazer previs√µes com novas reclama√ß√µes.

3. **[ ] Implementa√ß√£o de testes automatizados**: Ambiente deve ser cap√°z de validar fun√ß√µes principais, similar a um ambiente de produ√ß√£o.
